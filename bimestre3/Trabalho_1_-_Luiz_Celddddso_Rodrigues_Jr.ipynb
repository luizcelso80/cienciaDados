{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Trabalho 1 - Lista de Exercícios - 27/08/2018</b>\n",
    "<br><br>\n",
    "**Atenção**\n",
    "<ul>\n",
    "    <li>Os datasets a serem utilizados neste trabalho estão no FibOnline e na rede, na pasta \"Basseto/Farina\"\n",
    "    <li>Após o término do trabalho submeter no FibOnline no formato Jupyter Notebook (.ipynb)\n",
    "    <li>O prazo final para envio é 03/09/2018, às 19:00 h. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Atividade 1</b>\n",
    "Desenvolva um modelo preditivo baseado no classificador **KNN** para que, dado as característica uma semente de trigo, consiga classificar entre os tipos Kama, Rosa e Canadian. Considere o dataset **seeds** para o seu modelo.<br>\n",
    "Calcule a <b>acurácia</b> do seu modelo alterando a quantidade de características (1 a 7) da semente bem como a quantidade de vizinhos a considerar (1 a 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sobre o Dataset:**\n",
    "\n",
    "A base de dados “seeds” foi obtida do repositório da UCI (https://archive.ics.uci.edu/ml/datasets/seeds), no formato textual (.txt). Ela é composta por 210 instâncias pertencentes a três classes, 70 instâncias cada, correspondendo respectivamente a cada uma das variedades de trigo: Kama, Rosa e Canadian. A tabela abaixo mostra os atributos de cada classe que correspondem às características do grão de trigo, totalizando sete atributos do tipo “real” e mais o campo enumerativo correspondente à classe (variedade do trigo).\n",
    "<br><br>\n",
    "Atributos de cada instância:\n",
    "1. Área \n",
    "2. Perímetro \n",
    "3. Compacidade (ou compactação),\n",
    "4. Comprimento do grão\n",
    "5. Largura do grão\n",
    "6. Coeficiente de assimetria\n",
    "7. Comprimento do sulco do grão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "data = np.genfromtxt('H:\\\\datasets\\\\seeds_dataset.txt', delimiter='', usecols=(0,1,2,3,4,5,6,7))\n",
    "\n",
    "\n",
    "seeds = [   ([c0,c1,c2,c3,c4,c5,c6],label) for c0, c1, c2, c3, c4, c5, c6, label in data]\n",
    "\n",
    "def majority_vote(labels):\n",
    "    \"\"\"assumes that labels are ordered from nearest to farthest\"\"\"\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count for count in vote_counts.values() if count == winner_count])\n",
    "    if num_winners == 1:\n",
    "        return winner # unique winner, so return it\n",
    "    else:\n",
    "        return majority_vote(labels[:-1]) # try again without the farthest\n",
    "\n",
    "def knn_classify(k, labeled_points, new_point):\n",
    "    \"\"\"each labeled point should be a pair (point, label)\"\"\"\n",
    "    # order the labeled points from nearest to farthest\n",
    "    by_distance = sorted(labeled_points, key=lambda point: distance.euclidean(point[0], new_point))\n",
    "    # find the labels for the k closest\n",
    "    k_nearest_labels = [label for _, label in by_distance[:k]]\n",
    "    # and let them vote\n",
    "    return majority_vote(k_nearest_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbor[s]: 1 atributes[s]: 175 correct out of 210\n",
      "1 neighbor[s]: 2 atributes[s]: 172 correct out of 210\n",
      "1 neighbor[s]: 3 atributes[s]: 172 correct out of 210\n",
      "1 neighbor[s]: 4 atributes[s]: 175 correct out of 210\n",
      "1 neighbor[s]: 5 atributes[s]: 175 correct out of 210\n",
      "1 neighbor[s]: 6 atributes[s]: 189 correct out of 210\n",
      "1 neighbor[s]: 7 atributes[s]: 190 correct out of 210\n",
      "2 neighbor[s]: 1 atributes[s]: 175 correct out of 210\n",
      "2 neighbor[s]: 2 atributes[s]: 172 correct out of 210\n",
      "2 neighbor[s]: 3 atributes[s]: 172 correct out of 210\n",
      "2 neighbor[s]: 4 atributes[s]: 175 correct out of 210\n",
      "2 neighbor[s]: 5 atributes[s]: 175 correct out of 210\n",
      "2 neighbor[s]: 6 atributes[s]: 189 correct out of 210\n",
      "2 neighbor[s]: 7 atributes[s]: 190 correct out of 210\n",
      "3 neighbor[s]: 1 atributes[s]: 179 correct out of 210\n",
      "3 neighbor[s]: 2 atributes[s]: 177 correct out of 210\n",
      "3 neighbor[s]: 3 atributes[s]: 177 correct out of 210\n",
      "3 neighbor[s]: 4 atributes[s]: 171 correct out of 210\n",
      "3 neighbor[s]: 5 atributes[s]: 170 correct out of 210\n",
      "3 neighbor[s]: 6 atributes[s]: 186 correct out of 210\n",
      "3 neighbor[s]: 7 atributes[s]: 186 correct out of 210\n",
      "4 neighbor[s]: 1 atributes[s]: 179 correct out of 210\n",
      "4 neighbor[s]: 2 atributes[s]: 177 correct out of 210\n",
      "4 neighbor[s]: 3 atributes[s]: 177 correct out of 210\n",
      "4 neighbor[s]: 4 atributes[s]: 171 correct out of 210\n",
      "4 neighbor[s]: 5 atributes[s]: 170 correct out of 210\n",
      "4 neighbor[s]: 6 atributes[s]: 186 correct out of 210\n",
      "4 neighbor[s]: 7 atributes[s]: 186 correct out of 210\n",
      "5 neighbor[s]: 1 atributes[s]: 170 correct out of 210\n",
      "5 neighbor[s]: 2 atributes[s]: 175 correct out of 210\n",
      "5 neighbor[s]: 3 atributes[s]: 175 correct out of 210\n",
      "5 neighbor[s]: 4 atributes[s]: 175 correct out of 210\n",
      "5 neighbor[s]: 5 atributes[s]: 177 correct out of 210\n",
      "5 neighbor[s]: 6 atributes[s]: 184 correct out of 210\n",
      "5 neighbor[s]: 7 atributes[s]: 184 correct out of 210\n",
      "6 neighbor[s]: 1 atributes[s]: 170 correct out of 210\n",
      "6 neighbor[s]: 2 atributes[s]: 175 correct out of 210\n",
      "6 neighbor[s]: 3 atributes[s]: 175 correct out of 210\n",
      "6 neighbor[s]: 4 atributes[s]: 175 correct out of 210\n",
      "6 neighbor[s]: 5 atributes[s]: 177 correct out of 210\n",
      "6 neighbor[s]: 6 atributes[s]: 184 correct out of 210\n",
      "6 neighbor[s]: 7 atributes[s]: 184 correct out of 210\n",
      "7 neighbor[s]: 1 atributes[s]: 166 correct out of 210\n",
      "7 neighbor[s]: 2 atributes[s]: 176 correct out of 210\n",
      "7 neighbor[s]: 3 atributes[s]: 176 correct out of 210\n",
      "7 neighbor[s]: 4 atributes[s]: 177 correct out of 210\n",
      "7 neighbor[s]: 5 atributes[s]: 178 correct out of 210\n",
      "7 neighbor[s]: 6 atributes[s]: 184 correct out of 210\n",
      "7 neighbor[s]: 7 atributes[s]: 188 correct out of 210\n",
      "8 neighbor[s]: 1 atributes[s]: 166 correct out of 210\n",
      "8 neighbor[s]: 2 atributes[s]: 176 correct out of 210\n",
      "8 neighbor[s]: 3 atributes[s]: 176 correct out of 210\n",
      "8 neighbor[s]: 4 atributes[s]: 177 correct out of 210\n",
      "8 neighbor[s]: 5 atributes[s]: 178 correct out of 210\n",
      "8 neighbor[s]: 6 atributes[s]: 184 correct out of 210\n",
      "8 neighbor[s]: 7 atributes[s]: 188 correct out of 210\n",
      "9 neighbor[s]: 1 atributes[s]: 170 correct out of 210\n",
      "9 neighbor[s]: 2 atributes[s]: 178 correct out of 210\n",
      "9 neighbor[s]: 3 atributes[s]: 178 correct out of 210\n",
      "9 neighbor[s]: 4 atributes[s]: 178 correct out of 210\n",
      "9 neighbor[s]: 5 atributes[s]: 176 correct out of 210\n",
      "9 neighbor[s]: 6 atributes[s]: 188 correct out of 210\n",
      "9 neighbor[s]: 7 atributes[s]: 190 correct out of 210\n",
      "10 neighbor[s]: 1 atributes[s]: 170 correct out of 210\n",
      "10 neighbor[s]: 2 atributes[s]: 178 correct out of 210\n",
      "10 neighbor[s]: 3 atributes[s]: 178 correct out of 210\n",
      "10 neighbor[s]: 4 atributes[s]: 178 correct out of 210\n",
      "10 neighbor[s]: 5 atributes[s]: 176 correct out of 210\n",
      "10 neighbor[s]: 6 atributes[s]: 188 correct out of 210\n",
      "10 neighbor[s]: 7 atributes[s]: 190 correct out of 210\n",
      "11 neighbor[s]: 1 atributes[s]: 176 correct out of 210\n",
      "11 neighbor[s]: 2 atributes[s]: 177 correct out of 210\n",
      "11 neighbor[s]: 3 atributes[s]: 177 correct out of 210\n",
      "11 neighbor[s]: 4 atributes[s]: 179 correct out of 210\n",
      "11 neighbor[s]: 5 atributes[s]: 178 correct out of 210\n",
      "11 neighbor[s]: 6 atributes[s]: 188 correct out of 210\n",
      "11 neighbor[s]: 7 atributes[s]: 191 correct out of 210\n",
      "12 neighbor[s]: 1 atributes[s]: 176 correct out of 210\n",
      "12 neighbor[s]: 2 atributes[s]: 177 correct out of 210\n",
      "12 neighbor[s]: 3 atributes[s]: 177 correct out of 210\n",
      "12 neighbor[s]: 4 atributes[s]: 179 correct out of 210\n",
      "12 neighbor[s]: 5 atributes[s]: 178 correct out of 210\n",
      "12 neighbor[s]: 6 atributes[s]: 188 correct out of 210\n",
      "12 neighbor[s]: 7 atributes[s]: 191 correct out of 210\n",
      "13 neighbor[s]: 1 atributes[s]: 181 correct out of 210\n",
      "13 neighbor[s]: 2 atributes[s]: 181 correct out of 210\n",
      "13 neighbor[s]: 3 atributes[s]: 181 correct out of 210\n",
      "13 neighbor[s]: 4 atributes[s]: 179 correct out of 210\n",
      "13 neighbor[s]: 5 atributes[s]: 180 correct out of 210\n",
      "13 neighbor[s]: 6 atributes[s]: 188 correct out of 210\n",
      "13 neighbor[s]: 7 atributes[s]: 190 correct out of 210\n"
     ]
    }
   ],
   "source": [
    "knn_classify(7, seeds, [20.24, 16.91, 0.8897, 6.315, 3.962, 5.901, 6.188])\n",
    "\n",
    "for k in range(1,14):\n",
    "    \n",
    "    for attr in range(1,8):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for seed in seeds:\n",
    "            \n",
    "            location, actual_language = seed\n",
    "            other_seeds = [(carac[0:attr], label) for carac, label in seeds if (carac, label) != seed]\n",
    "            \n",
    "            predicted_language = knn_classify(k, other_seeds, location[0:attr])\n",
    "            if predicted_language == actual_language:\n",
    "                num_correct += 1\n",
    "        print (k, \"neighbor[s]:\", attr, \"atributes[s]:\", num_correct, \"correct out of\", len(seeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Atividade 2</b>\n",
    "Desenvolva um modelo preditivo baseado no classificador **Naive Bayes** para que, dado a letra de uma música, consiga classificar entre os gêneros **Bossa Nova, Funk, Sertanejo e Gospel**. O dataset com as músicas será fornecido, ele é composto de letras de músicas de acordo com a sua classificação de gênero.<br>\n",
    "Exiba os valores do <b>Precision, Recall e F1-Score</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(message):\n",
    "    message = message.lower() # convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9']+\", message) # extract the words\n",
    "    return set(all_words) # remove duplicates\n",
    "\n",
    "def count_words(training_set):\n",
    "    \"\"\"training set consists of pairs (message, is_spam)\"\"\"\n",
    "    counts = defaultdict(lambda: [0, 0, 0, 0])\n",
    "    for lyrics, genero in training_set:\n",
    "        for word in tokenize(lyrics):\n",
    "            counts[word][genero] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probabilities(counts, total_bossa, total_funk, total_sertanejo, total_gospel, k=0.5):\n",
    "    \"\"\"turn the word_counts into a list of triplets w, p(w | spam) and p(w | ~spam)\"\"\"\n",
    "    return [(w,\n",
    "            (bossa + k) / (total_bossa + 2 * k),\n",
    "            (funk + k) / (total_funk + 2 * k),\n",
    "            (sertanejo + k) / (total_sertanejo + 2 * k),\n",
    "            (gospel + k) / (total_gospel + 2 * k))\n",
    "            for w, (bossa, funk, sertanejo, gospel) in counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_probability(word_probs, message):\n",
    "    message_words = tokenize(message)\n",
    "    log_prob_if_bossa = log_prob_if_funk = log_prob_if_sertanejo = log_prob_if_gospel = 0.0\n",
    "    \n",
    "    # iterate through each word in our vocabulary\n",
    "    for word, prob_if_bossa, prob_if_funk, prob_if_sertanejo, prob_if_gospel in word_probs:\n",
    "        # if *word* appears in the message,\n",
    "        # add the log probability of seeing it\n",
    "        if word in message_words:\n",
    "            log_prob_if_bossa += math.log(prob_if_bossa)\n",
    "            log_prob_if_funk += math.log(prob_if_funk)\n",
    "            log_prob_if_sertanejo += math.log(prob_if_sertanejo)\n",
    "            log_prob_if_gospel += math.log(prob_if_gospel)\n",
    "        # if *word* doesn't appear in the message\n",
    "        # add the log probability of _not_ seeing it\n",
    "        # which is log(1 - probability of seeing it)\n",
    "        else:\n",
    "            log_prob_if_bossa += math.log(1.0 - prob_if_bossa)\n",
    "            log_prob_if_funk += math.log(1.0 - prob_if_funk)\n",
    "            log_prob_if_sertanejo += math.log(1.0 - prob_if_sertanejo)\n",
    "            log_prob_if_gospel += math.log(1.0 - prob_if_gospel)\n",
    "    prob_if_bossa = math.exp(log_prob_if_bossa)\n",
    "    prob_if_funk = math.exp(log_prob_if_funk)\n",
    "    prob_if_sertanejo = math.exp(log_prob_if_sertanejo)\n",
    "    prob_if_gospel = math.exp(log_prob_if_gospel)\n",
    "    prob_total = prob_if_bossa + prob_if_funk + prob_if_sertanejo + prob_if_gospel\n",
    "    if prob_total==0: return [0,0,0,0]\n",
    "    resultado = [prob_if_bossa / prob_total, prob_if_funk / prob_total, prob_if_sertanejo / prob_total, prob_if_gospel / prob_total]\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "# modify the path with wherever you've put the files\n",
    "path = r\"H:\\datasets\\lyrics\\*\"\n",
    "data = []\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for fn in glob.glob(path):\n",
    "    lyric = ''\n",
    "    genre = 0 if \"bossa\" in fn else 1 if \"funk\" in fn else 2 if \"sertanejo\" in fn else 3 if \"gospel\" in fn else -1\n",
    "    is_spam = \"ham\" not in fn\n",
    "    \n",
    "    with open(fn,'r', encoding=\"utf8\", errors='ignore') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"lyric\"):\n",
    "                continue\n",
    "            elif line.startswith('\"'):\n",
    "                if not lyric:\n",
    "                    continue\n",
    "                else:\n",
    "                    data.append((lyric, genre))\n",
    "                    lyric = ''\n",
    "            else:\n",
    "                lyric += line.replace('\"', '').replace(\"'\", \"\").rstrip().lstrip() + ' '\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "    def train(self, training_set):\n",
    "        # count spam and non-spam messages\n",
    "        num_bossa = len([is_bossa\n",
    "                        for lyric, is_bossa in training_set\n",
    "                        if is_bossa == 0])\n",
    "        num_funk = len([is_funk\n",
    "                        for lyric, is_funk in training_set\n",
    "                        if is_funk == 1])\n",
    "        num_sertanejo = len([is_sertanejo\n",
    "                        for lyric, is_sertanejo in training_set\n",
    "                        if is_sertanejo == 2])\n",
    "        num_gospel = len([is_gospel\n",
    "                        for lyric, is_gospel in training_set\n",
    "                        if is_gospel == 3])\n",
    "        \n",
    "        \n",
    "        # run training data through our \"pipeline\"\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts,\n",
    "                                            num_bossa,\n",
    "                                            num_funk,\n",
    "                                            num_sertanejo,\n",
    "                                            num_gospel,\n",
    "                                            self.k)\n",
    "    def classify(self, message):\n",
    "        return spam_probability(self.word_probs, message)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import math\n",
    "def split_data(data, prob):\n",
    "    \"\"\"dividi os dados em fracoes [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "random.seed(0)\n",
    "train_data, test_data = split_data(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0007036755008242429, 2.419451923912453e-07, 0.00018227937122204449, 0.9991138031827613]\n"
     ]
    }
   ],
   "source": [
    "classificacao = classifier.classify(\"Não conte os teus maiores sonhos a ninguém Não mostre a sua ferida para quem não tem Remédio pra curá-la e forças para te erguer Não não não não\")\n",
    "print(classificacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "v = [num for num in range(4)]\n",
    "\n",
    "print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "counts = Counter([ (genero == gen, classifier.classify(lyric)[gen] > 0.5 )\n",
    "          for lyric, genero in test_data for gen in range(4)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 2345, (True, True): 680, (True, False): 146, (False, True): 133})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8364083640836408\n",
      "0.8232445520581114\n",
      "0.8297742525930446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def precision(tp, fp, fn, tn):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp, fp, fn, tn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(tp, fp, fn, tn):\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2 * p * r / (p + r)\n",
    "\n",
    "# tp=tt fp=ft fn=tf tn=ff\n",
    "\n",
    "print (precision(680,133,146,2345))\n",
    "print (recall(680,133,146,2345))\n",
    "print (f1_score(680,133,146,2345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prob = dict(Counter((genre, 0 if probs[0] > 0.5 else 1 ifprobs[1] > 0.5 else 2 if probs[2] > 0.5 else 3 if probs[3] > 0.5 else 5)\n",
    "                        for _, genre, probs in classified))\n",
    "cm = [[0 for x in range(4)] for y in range(4)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
